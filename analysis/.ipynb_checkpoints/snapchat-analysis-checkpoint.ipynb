{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapchat Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Requisite Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying for spatial base-map imagery using ArcGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "m = Basemap(llcrnrlon=76.838069, llcrnrlat=28.412593,\n",
    "        urcrnrlon=77.348458, urcrnrlat=28.881338)\n",
    " \n",
    "lons, lats, x, y = m.makegrid(30, 30, returnxy=True)\n",
    "\n",
    "m.drawparallels(range(0, 90, 20))\n",
    "# m.scatter(x, y)\n",
    "m.drawcoastlines()\n",
    "\n",
    "m.arcgisimage(service='ESRI_Imagery_World_2D', verbose=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying ArcGIS Server for base-maps of all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import pi, cos\n",
    "import matplotlib.ticker as pltticker\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "RADIUS_EARTH = 6378 # in kilometers\n",
    "TILE_SIZE = 2.500 # the tile size in the grid (in kilometers)\n",
    "\n",
    "# cities_df = pd.read_csv('cities.csv')\n",
    "# for i in range(len(cities_df)):\n",
    "#     city = cities_df.loc[i][\"City\"]\n",
    "#     SW_LAT = cities_df.loc[i][\"Lat (Southwest)\"]\n",
    "#     NE_LAT = cities_df.loc[i][\"Lat (Northeast)\"]\n",
    "#     SW_LNG = cities_df.loc[i][\"Lon (Southwest)\"]\n",
    "#     NE_LNG = cities_df.loc[i][\"Lon (Northeast)\"]\n",
    "\n",
    "SW_LAT = 76.838069\n",
    "SW_LNG = 28.412593\n",
    "NE_LAT = 77.348458\n",
    "NE_LNG = 28.881338\n",
    "\n",
    "lat_change = (TILE_SIZE / ((2 * pi/360) * RADIUS_EARTH))\n",
    "lng_change = (TILE_SIZE / ((2 * pi/360) * RADIUS_EARTH)) / cos(((SW_LAT + NE_LAT) / 2) * pi/180)\n",
    "\n",
    "basemap_url = \"http://server.arcgisonline.com/ArcGIS/rest/services/ESRI_Imagery_World_2D/MapServer/export?bbox=%f,%f,%f,%f&bboxSR=104013&imageSR=104013&dpi=96&format=png32&f=image\" % (SW_LAT, SW_LNG, NE_LAT, NE_LNG)\n",
    "\n",
    "lats = np.arange(SW_LAT, NE_LAT, lat_change)\n",
    "lngs = np.arange(SW_LNG, NE_LNG, lat_change)\n",
    "\n",
    "fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "\n",
    "ax.xaxis.set_major_locator(plticker.LinearLocator(numticks=len(lats)))\n",
    "ax.yaxis.set_major_locator(plticker.LinearLocator(numticks=len(lngs)))\n",
    "\n",
    "ax.set_xticklabels(lats, fontsize=9)\n",
    "ax.set_yticklabels(lngs, fontsize=9)\n",
    "\n",
    "plt.xticks(rotation=75)\n",
    "\n",
    "plt.imshow(plt.imread(urlopen(basemap_url)), origin='upper') \n",
    "plt.grid()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# In a notebook environment, display the plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set some parameters to apply to all plots. These can be overridden\n",
    "# in each plot if desired\n",
    "# import matplotlib\n",
    "# Plot size to 14\" x 7\"\n",
    "matplotlib.rc('figure', figsize = (10, 8))\n",
    "# Font size to 14\n",
    "matplotlib.rc('font', size = 24)\n",
    "# Do not display top and right frame lines\n",
    "matplotlib.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "matplotlib.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "matplotlib.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Model Accuracy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/shwetanshusingh/Desktop/Snapchat/robustness.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black', 'grey']\n",
    "positions = [0, 1]\n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "\n",
    "for group, color, pos in zip(df.groupby('WideResNet'), colors, positions):\n",
    "    key, group = group\n",
    "    group.plot('Threshold', 'mean_accuracy', yerr='dev_accuracy', kind='bar', width=0.4, label=key, \n",
    "               position=pos, color=color, alpha=0.5, ax=ax, error_kw=dict(lw=3, capsize=5, capthick=1.5))\n",
    "\n",
    "ax.yaxis.set_label_text('Accuracy')\n",
    "ax.set_ylim(0, 1.05)    \n",
    "ax.set_xlim(-0.71, 4.5)\n",
    "plt.xticks(rotation=0)\n",
    "fig.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('/Users/shwetanshusingh/Desktop/accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import class-wise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/shwetanshusingh/Desktop/Snapchat/class-wise.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black', 'grey', 'blue']\n",
    "positions = [0, 1, 2]\n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "\n",
    "for group, color, pos in zip(df.groupby('Models'), colors, positions):\n",
    "    key, group = group\n",
    "    group.plot('Type', 'mean_recall', yerr='dev_recall', kind='bar', width=0.3, label=key, \n",
    "               position=pos, color=color, alpha=0.5, ax=ax, error_kw=dict(lw=3, capsize=5, capthick=1.5))\n",
    "\n",
    "ax.yaxis.set_label_text('Recall')\n",
    "ax.set_ylim(0.85, 1.025)    \n",
    "ax.set_xlim(-0.75, 1.5)\n",
    "plt.xticks(rotation=0)\n",
    "fig.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('/Users/shwetanshusingh/Desktop/classwise-recall.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import prediction results data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>local_timestamp</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>url</th>\n",
       "      <th>non_driving</th>\n",
       "      <th>local_date</th>\n",
       "      <th>local_time</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>local_minute</th>\n",
       "      <th>local_second</th>\n",
       "      <th>local_weekday</th>\n",
       "      <th>local_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAY3AiPrLhH65pdAWmCqu4nA...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.674125</td>\n",
       "      <td>77.064029</td>\n",
       "      <td>1552674600000</td>\n",
       "      <td>2019-03-16 00:00:00</td>\n",
       "      <td>16_03_2019</td>\n",
       "      <td>9.296667</td>\n",
       "      <td>https://s.sc-cdn.net/c8AAKzM0ru6kt8ftIHTCod001...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYmSj9OwxbeKXrAWmCqul9A...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.674125</td>\n",
       "      <td>77.064029</td>\n",
       "      <td>1552674600000</td>\n",
       "      <td>2019-03-16 00:00:00</td>\n",
       "      <td>16_03_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/MoZ5SufxR6oQNk32WBYBu8o4Z...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYmJ1wsiKtCM_uAWmDYGmiA...</td>\n",
       "      <td>Amman</td>\n",
       "      <td>31.953270</td>\n",
       "      <td>35.912186</td>\n",
       "      <td>1552687200000</td>\n",
       "      <td>2019-03-16 00:00:00</td>\n",
       "      <td>16_03_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/FqdN13UMj9SOpvXTZAH_mp90-...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAY7tay4k7ISEREAWmCoJ7-A...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19.064640</td>\n",
       "      <td>72.871390</td>\n",
       "      <td>1552674600000</td>\n",
       "      <td>2019-03-16 00:00:00</td>\n",
       "      <td>16_03_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/qH7cPflldGHu88ettD-GWS3Uq...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAY3VSbhsZ7kE2ZAWmCns9sA...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19.046673</td>\n",
       "      <td>72.899907</td>\n",
       "      <td>1552674600000</td>\n",
       "      <td>2019-03-16 00:00:00</td>\n",
       "      <td>16_03_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/JI29SEAn7MWkkDtbsx70cDqES...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id    city        lat  \\\n",
       "0  W7_EDlXWTBiXAEEniNoMPwAAY3AiPrLhH65pdAWmCqu4nA...   Delhi  28.674125   \n",
       "1  W7_EDlXWTBiXAEEniNoMPwAAYmSj9OwxbeKXrAWmCqul9A...   Delhi  28.674125   \n",
       "2  W7_EDlXWTBiXAEEniNoMPwAAYmJ1wsiKtCM_uAWmDYGmiA...   Amman  31.953270   \n",
       "3  W7_EDlXWTBiXAEEniNoMPwAAY7tay4k7ISEREAWmCoJ7-A...  Mumbai  19.064640   \n",
       "4  W7_EDlXWTBiXAEEniNoMPwAAY3VSbhsZ7kE2ZAWmCns9sA...  Mumbai  19.046673   \n",
       "\n",
       "         lon  utc_timestamp      local_timestamp scraped_date   duration  \\\n",
       "0  77.064029  1552674600000  2019-03-16 00:00:00   16_03_2019   9.296667   \n",
       "1  77.064029  1552674600000  2019-03-16 00:00:00   16_03_2019  10.000000   \n",
       "2  35.912186  1552687200000  2019-03-16 00:00:00   16_03_2019  10.000000   \n",
       "3  72.871390  1552674600000  2019-03-16 00:00:00   16_03_2019  10.000000   \n",
       "4  72.899907  1552674600000  2019-03-16 00:00:00   16_03_2019  10.000000   \n",
       "\n",
       "                                                 url  non_driving  local_date  \\\n",
       "0  https://s.sc-cdn.net/c8AAKzM0ru6kt8ftIHTCod001...            1  2019-03-16   \n",
       "1  https://s.sc-cdn.net/MoZ5SufxR6oQNk32WBYBu8o4Z...            1  2019-03-16   \n",
       "2  https://s.sc-cdn.net/FqdN13UMj9SOpvXTZAH_mp90-...            1  2019-03-16   \n",
       "3  https://s.sc-cdn.net/qH7cPflldGHu88ettD-GWS3Uq...            1  2019-03-16   \n",
       "4  https://s.sc-cdn.net/JI29SEAn7MWkkDtbsx70cDqES...            1  2019-03-16   \n",
       "\n",
       "  local_time  local_hour  local_minute  local_second local_weekday  local_day  \n",
       "0   00:00:00           0             0             0      Saturday         16  \n",
       "1   00:00:00           0             0             0      Saturday         16  \n",
       "2   00:00:00           0             0             0      Saturday         16  \n",
       "3   00:00:00           0             0             0      Saturday         16  \n",
       "4   00:00:00           0             0             0      Saturday         16  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"combined_v5.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute data by class & hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_driving</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>driving</td>\n",
       "      <td>0</td>\n",
       "      <td>81935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>driving</td>\n",
       "      <td>1</td>\n",
       "      <td>64256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>driving</td>\n",
       "      <td>2</td>\n",
       "      <td>49212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>driving</td>\n",
       "      <td>3</td>\n",
       "      <td>34322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>driving</td>\n",
       "      <td>4</td>\n",
       "      <td>21259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  non_driving  local_hour  count\n",
       "0     driving           0  81935\n",
       "1     driving           1  64256\n",
       "2     driving           2  49212\n",
       "3     driving           3  34322\n",
       "4     driving           4  21259"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.groupby(['non_driving', 'local_hour']).count()['id'].reset_index()\n",
    "\n",
    "data.rename(columns={'id': 'count'}, inplace=True)\n",
    "data.non_driving.replace(0, 'driving', inplace=True)\n",
    "data.non_driving.replace(1, 'non-driving', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 81935, 231464],\n",
       "       [ 64256, 191337],\n",
       "       [ 49212, 132524],\n",
       "       [ 34322,  81808],\n",
       "       [ 21259,  49673],\n",
       "       [ 19952,  40451],\n",
       "       [ 36214,  56197],\n",
       "       [ 46024,  75695],\n",
       "       [ 43962,  98167],\n",
       "       [ 46085, 129073],\n",
       "       [ 50940, 164400],\n",
       "       [ 57933, 194310],\n",
       "       [ 58806, 211742],\n",
       "       [ 68355, 236904],\n",
       "       [ 74139, 247603],\n",
       "       [ 64073, 238103],\n",
       "       [ 73780, 252610],\n",
       "       [ 89399, 288834],\n",
       "       [ 82655, 311395],\n",
       "       [ 81502, 329552],\n",
       "       [ 80421, 347832],\n",
       "       [ 99634, 377141],\n",
       "       [100303, 357780],\n",
       "       [ 90189, 271608]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours_list = [[0, 0] for a in range(24)]\n",
    "for i, row in data.iterrows():\n",
    "    hour = row[\"local_hour\"]\n",
    "    if row[\"non_driving\"] == \"driving\":\n",
    "        hours_list[hour][0] = row[\"count\"]\n",
    "    else:\n",
    "        hours_list[hour][1] = row[\"count\"]\n",
    "\n",
    "hours_list = np.array(hours_list)\n",
    "hours_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.95451707],\n",
       "       [0.95451707, 1.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(hours_list[:, 0], hours_list[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute daytime and night-time driving ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_driving</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>driving</td>\n",
       "      <td>0</td>\n",
       "      <td>81935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>driving</td>\n",
       "      <td>1</td>\n",
       "      <td>64256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>driving</td>\n",
       "      <td>2</td>\n",
       "      <td>49212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>driving</td>\n",
       "      <td>18</td>\n",
       "      <td>82655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>driving</td>\n",
       "      <td>19</td>\n",
       "      <td>81502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non_driving  local_hour  count\n",
       "0      driving           0  81935\n",
       "1      driving           1  64256\n",
       "2      driving           2  49212\n",
       "18     driving          18  82655\n",
       "19     driving          19  81502"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = data[(data[\"non_driving\"] == \"driving\") & ((data[\"local_hour\"] >= 18) | ((data[\"local_hour\"] >= 0) & (data[\"local_hour\"] <= 2)))]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute daytime and nigh-time ratio for all snaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_hour</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>313399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>255593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>181736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>116130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>70932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   local_hour   count\n",
       "0           0  313399\n",
       "1           1  255593\n",
       "2           2  181736\n",
       "3           3  116130\n",
       "4           4   70932"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.groupby(['local_hour']).count()['id'].reset_index()\n",
    "\n",
    "data.rename(columns={'id': 'count'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_hour</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>313399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>255593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>181736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>394050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>411054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    local_hour   count\n",
       "0            0  313399\n",
       "1            1  255593\n",
       "2            2  181736\n",
       "18          18  394050\n",
       "19          19  411054"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = data[(data[\"local_hour\"] >= 18) | ((data[\"local_hour\"] >= 0) & (data[\"local_hour\"] <= 2))]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "ax = sns.lmplot(data=data, x='local_hour', y='count', hue='non_driving', \n",
    "               fit_reg=True, order=3, legend=False, markers=['x', 'o'], height=7, aspect=1.2)\n",
    "ax.set(xlabel='Hour of the day', ylabel='Number of Snaps')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim([0, 24])\n",
    "\n",
    "ax.set(yticks=[100000, 200000, 300000, 400000, 500000], yticklabels=['100k', '200k', '300k', '400k', '500k'])\n",
    "\n",
    "ax.savefig('plots/diurnal.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of the week analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_saturdays = 5\n",
    "num_sundays = 5\n",
    "num_mondays = 5\n",
    "num_tuesdays = 4\n",
    "num_wednesdays = 4 \n",
    "num_thursdays = 4\n",
    "num_fridays = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.groupby(['non_driving', 'local_weekday']).count()['id'].reset_index()\n",
    "\n",
    "data.rename(columns={'id': 'count'}, inplace=True)\n",
    "data.non_driving.replace(0, 'driving', inplace=True)\n",
    "data.non_driving.replace(1, 'non-driving', inplace=True)\n",
    "data.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in data.iterrows():\n",
    "    local_weekday = row['local_weekday']\n",
    "    count = row['count']\n",
    "    if local_weekday in [\"Friday\", \"Thursday\", \"Wednesday\", \"Tuesday\"]:\n",
    "        data.at[i, 'count'] = count / 4\n",
    "    else:\n",
    "        data.at[i, 'count'] = count / 5\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_dims = (11.7, 8.27)\n",
    "sns.set(rc={'figure.figsize':a4_dims}, font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "ax = sns.barplot(x=\"local_weekday\", y=\"count\", hue=\"non_driving\", data=data)\n",
    "\n",
    "ax.set(xlabel='Day of the Week', ylabel='Number of Snaps')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.savefig('/home/shashanks/Projects/analysis/dayodtheweek.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of the month analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.groupby(['non_driving', 'local_day']).count()['id'].reset_index()\n",
    "\n",
    "data.rename(columns={'id': 'count'}, inplace=True)\n",
    "data.non_driving.replace(0, 'driving', inplace=True)\n",
    "data.non_driving.replace(1, 'non-driving', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_dims = (20, 8.27)\n",
    "sns.set(rc={'figure.figsize':a4_dims}, font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "order = sorted(range(1, 32))\n",
    "\n",
    "ax = sns.barplot(x=\"local_day\", y=\"count\", hue=\"non_driving\", data=data, order=order)\n",
    "ax.set(xlabel='Day of the Month', ylabel='Number of Snaps')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('/home/shashanks/Projects/analysis/dayodthemoth.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add secondary computations by various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.groupby(['non_driving', 'local_hour']).count()['id'].unstack(level=0)\n",
    "\n",
    "# data.rename(index={'0': 'driving', '1': 'non-driving'}, inplace=True)\n",
    "data['driving_percent_class'] = data.ix[:,0:].sum(axis=1)/np.sum(data.ix[:,0:].values) * 100\n",
    "data['non_driving_percent_class'] = data.ix[:,1:].sum(axis=1)/np.sum(data.ix[:,1:].values) * 100\n",
    "data['driving_percent_overall'] = data[0] * 100 / len(df)\n",
    "data['non_driving_percent_overall'] = data[1] * 100 / len(df)\n",
    "data['driving_percent_hourly'] = data[0] * 100 / (data[0] + data[1])\n",
    "data['non_driving_percent_hourly'] = data[1] * 100 / (data[0] + data[1])\n",
    "\n",
    "data.reset_index(level=0, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_class = data[['driving_percent_class', 'non_driving_percent_class']].unstack(level=1).reset_index()\n",
    "percent_class.rename(columns={'level_1': 'hour', 0: 'percent'}, inplace=True)\n",
    "\n",
    "ax = sns.lmplot(data=percent_class, x='hour', y='percent', hue='non_driving', \n",
    "               fit_reg=True, order=3, legend=False, markers=['x', 'o'])\n",
    "ax.set(xlabel='Hour of the day', ylabel='Percent Class-wise')\n",
    "plt.legend(loc='upper left')\n",
    "ax.savefig('/home/shashanks/Projects/analysis/percent-class-wise.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "ax = data[['driving_percent_hourly', 'non_driving_percent_hourly']].plot(kind='bar', stacked=True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_class = data[['driving_percent_hourly', 'non_driving_percent_hourly']].unstack(level=1).reset_index()\n",
    "percent_class.rename(columns={'level_1': 'hour', 0: 'percent'}, inplace=True)\n",
    "\n",
    "ax = sns.lmplot(data=percent_class, x='hour', y='percent', hue='non_driving', \n",
    "               fit_reg=True, order=3, legend=False, markers=['x', 'o'])\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=1, mode=\"expand\", borderaxespad=0.)\n",
    "ax.savefig('/home/shashanks/Projects/analysis/percent-hourly.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_class = data[['driving_percent_overall', 'non_driving_percent_overall']].unstack(level=1).reset_index()\n",
    "percent_class.rename(columns={'level_1': 'hour', 0: 'value'}, inplace=True)\n",
    "percent_class.columns = ['non_driving', 'hour', 'percent']\n",
    "percent_class.columns\n",
    "\n",
    "ax = sns.lmplot(data=percent_class, x='hour', y='percent', hue='non_driving', \n",
    "               fit_reg=True, order=3, legend=False, markers=['x', 'o'])\n",
    "ax.set(xlabel='Hour of the day', ylabel='Percent Overall')\n",
    "plt.legend(loc='upper left')\n",
    "ax.savefig('/home/shashanks/Projects/analysis/percent-overall.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>non_driving</th>\n",
       "      <th>city</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>driving_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>9320</td>\n",
       "      <td>12437</td>\n",
       "      <td>0.428368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amritsar</td>\n",
       "      <td>6472</td>\n",
       "      <td>9180</td>\n",
       "      <td>0.413493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Riyadh</td>\n",
       "      <td>398276</td>\n",
       "      <td>599051</td>\n",
       "      <td>0.399343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Baghdad</td>\n",
       "      <td>37522</td>\n",
       "      <td>59074</td>\n",
       "      <td>0.388443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>4444</td>\n",
       "      <td>7372</td>\n",
       "      <td>0.376100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "non_driving        city       0       1  driving_percent\n",
       "39           Chandigarh    9320   12437         0.428368\n",
       "8              Amritsar    6472    9180         0.413493\n",
       "143              Riyadh  398276  599051         0.399343\n",
       "14              Baghdad   37522   59074         0.388443\n",
       "3             Ahmedabad    4444    7372         0.376100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_data = df.groupby(['non_driving', 'city']).count()['id'].unstack(level=0)\n",
    "city_data.reset_index(level=0, inplace=True)\n",
    "city_data['driving_percent'] = city_data[0] / (city_data[0] + city_data[1])\n",
    "city_data = city_data.sort_values(by=['driving_percent'], ascending=False)\n",
    "city_data = city_data[city_data[\"driving_percent\"] >= 0.197]\n",
    "city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "for i, row in city_data.iterrows():\n",
    "    x.append(row['city'])\n",
    "    y.append(row['driving_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_dims = (20, 10)\n",
    "plt.figure(figsize=a4_dims)\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "y_pos = range(len(x))\n",
    "\n",
    "ax = plt.bar(x=y_pos, height=y)\n",
    "plt.xlabel('City', fontsize=24)\n",
    "plt.ylabel('Percentage of Driving Snaps', fontsize=24)\n",
    "plt.xticks(y_pos, x, rotation=90, fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xlim([-1, 30])\n",
    "plt.savefig('plots/city-percent.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Grid Centers for each grid tile in each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_csv = pd.read_csv('grid_center.csv')\n",
    "grid_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data = df.groupby(['lat', 'lon']).count()['id'].reset_index()\n",
    "grid_data.rename(columns={'id': 'snap_count'}, inplace=True)\n",
    "grid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_grid_data = df[df.non_driving == 0].groupby(['lat', 'lon']).count()['id'].reset_index()\n",
    "driving_grid_data.rename(columns={'id': 'driving_count'}, inplace=True)\n",
    "driving_grid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data = pd.merge(grid_data, driving_grid_data, on=['lat', 'lon'], how='left')\n",
    "grid_data.driving_count.fillna(0.0, inplace=True)\n",
    "grid_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data = grid_data.merge(df[['city', 'lat', 'lon']].drop_duplicates(), on=['lat', 'lon'], how='left')\n",
    "grid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data_new = grid_data\n",
    "grid_data_new['driving_tile_percent'] = grid_data_new.driving_count * 100 / grid_data_new.snap_count\n",
    "grid_data_new['snap_city_percent'] = grid_data_new.snap_count * 100 / grid_data_new.groupby('city').snap_count.transform('sum')\n",
    "grid_data_new['driving_city_percent'] = grid_data_new.driving_count * 100 / grid_data_new.groupby('city').driving_count.transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data_new = grid_data_new[['city', 'lat', 'lon', 'snap_count', 'driving_count', 'driving_tile_percent', 'snap_city_percent', 'driving_city_percent']]\n",
    "grid_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data_new.to_csv(\"grid_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_tiles = grid_csv.groupby('city').tile_number.count() - grid_data.groupby('city').snap_count.count()\n",
    "num_zero_tiles = num_zero_tiles.reset_index()\n",
    "num_zero_tiles.rename(columns={0: \"num_zero\"}, inplace=True)\n",
    "num_zero_tiles.fillna(0.0, inplace=True)\n",
    "num_zero_tiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Analysis to check for Power Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in tqdm(grid_data.city.unique()):\n",
    "    plot_df = grid_data[grid_data.city == city]['snap_count'].reset_index().snap_count.value_counts().reset_index().sort_values(by='index', ascending=False)\n",
    "    print(plot_df.head())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in tqdm(grid_data.city.unique()):\n",
    "    plot_df = grid_data[grid_data.city == city]['snap_count'].reset_index().snap_count.value_counts().reset_index().sort_values(by='index', ascending=False)\n",
    "    plot_df.rename(columns={\"index\": \"snap_count\", \"snap_count\": \"# of tiles\"}, inplace=True)\n",
    "    ax = sns.lmplot(data=plot_df, x='snap_count', y='# of tiles', legend=False, markers='o', fit_reg=False)\n",
    "    ax.set(xlabel='Number of Snaps', ylabel='# of Tiles')\n",
    "    ax.savefig('./power_law/snap_count/' + str(city) + \"_power_law.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in tqdm(grid_data.city.unique()):\n",
    "    plot_df = grid_data[grid_data.city == city]['driving_count'].reset_index().driving_count.value_counts().reset_index().sort_values(by='index', ascending=False)\n",
    "    plot_df.rename(columns={\"index\": \"driving_count\", \"driving_count\": \"# of tiles\"}, inplace=True)\n",
    "    ax = sns.lmplot(data=plot_df, x='driving_count', y='# of tiles', legend=False, markers='o', fit_reg=False)\n",
    "    ax.set(xlabel='Number of Driving Snaps', ylabel='# of Tiles')\n",
    "    ax.savefig('./power_law/driving_count/' + str(city) + \"_driving_power_law.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Powerlaw Statistically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "\n",
    "with open('./power_law/driving_power_law_results.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(['city', 'alpha', 'xmin', 'sigma'])\n",
    "\n",
    "    for city in tqdm(grid_data.city.unique()):\n",
    "        plot_df = grid_data[grid_data.city == city]['driving_count'].reset_index().driving_count.value_counts().reset_index()\n",
    "        plot_df.rename(columns={\"index\": \"driving_count\", \"driving_count\": \"# of tiles\"}, inplace=True)\n",
    "        results = powerlaw.Fit(plot_df.driving_count)\n",
    "        csv_writer.writerow([city, results.power_law.alpha, results.power_law.xmin, results.power_law.sigma])\n",
    "\n",
    "# print(results.distribution_compare('power_law', 'exponential'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.distribution_compare('power_law', 'exponential'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlaw_df = pd.read_csv(\"./power_law/driving_power_law_results.csv\")\n",
    "powerlaw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('./power_law/driving_power_law_results.csv')\n",
    "ax = sns.lmplot(data=plot_df, x='xmin', y='alpha', legend=False, markers='o', fit_reg=False)\n",
    "# ax.set(xlim=(0, 100), ylim=(0, 20))\n",
    "\n",
    "# ax.savefig('/Users/shwetanshusingh/Desktop/Snapchat/power-law/power-law.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_csv = pd.merge(grid_csv, grid_data, on=['lat', 'lon'], how='left').fillna(0.0)\n",
    "grid_csv.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./power_law/total_power_law_results.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(['city', 'alpha', 'xmin', 'sigma'])\n",
    "\n",
    "    for city in tqdm(grid_data.city.unique()):\n",
    "        plot_df = grid_data[grid_data.city == city]['snap_count'].reset_index().snap_count.value_counts().reset_index()\n",
    "        plot_df.rename(columns={\"index\": \"snap_count\", \"snap_count\": \"# of tiles\"}, inplace=True)\n",
    "        results = powerlaw.Fit(plot_df.snap_count)\n",
    "        csv_writer.writerow([city, results.power_law.alpha, results.power_law.xmin, results.power_law.sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlaw_df = pd.read_csv(\"./power_law/total_power_law_results.csv\")\n",
    "powerlaw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_wise = grid_data.groupby('city').sum()[['snap_count', 'driving_count']]\n",
    "city_wise['percent_driving'] = city_wise.driving_count * 100 / city_wise.snap_count\n",
    "city_wise.reset_index(inplace=True)\n",
    "city_wise = city_wise.merge(grid_data.groupby('city').lat.count().reset_index().rename(columns={'lat': 'tile_data_count'}))\n",
    "city_wise = city_wise.merge(grid_csv.groupby('city').count()['tile_number'].reset_index())\n",
    "city_wise['percent_data_tiles'] = city_wise.tile_data_count * 100 / city_wise.tile_number\n",
    "city_wise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=city_wise, x='percent_driving', y='percent_data_tiles', legend=False)\n",
    "# ax = sns.lmplot(data=plot_df, x='snap_count', y='# of tiles', legend=False, markers='o', fit_reg=False)\n",
    "ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set(xlabel='% Driving', ylabel='% Tiles with Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data=city_wise, x='driving_count', y='tile_data_count', legend=False)\n",
    "# markers='o', fit_reg=False)\n",
    "ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set(xlabel='# Driving Snaps', ylabel='# Tiles with Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.non_driving == 0].duration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df.non_driving == 0].duration)\n",
    "ax = sns.distplot(df[df.non_driving == 1].duration)\n",
    "ax.set(xlabel='Duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['local_date'] = df.local_date.apply(lambda x: dt.strftime(x, '%Y-%m-%d'))\n",
    "df.local_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"duration\", y=\"local_date\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"duration\", y=\"local_date\", data=df, hue='non_driving', kind=\"boxen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"duration\", y=\"local_date\", data=df, hue='non_driving', kind='violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import pareto, powerlaw as spl\n",
    "\n",
    "fw = open('/Users/shwetanshusingh/Desktop/Snapchat/power-law/SUMMARY_PLFits.csv','w')\n",
    "for city in tqdm(grid_data.city.unique()):\n",
    "\n",
    "#     print(\"City=\" + str(city))\n",
    "    data = grid_data[grid_data.city == city]['driving_count'].values\n",
    "    params = spl.fit(data)\n",
    "    rvs = spl.rvs(params[0], params[1], params[2], size=len(data))\n",
    "\n",
    "    y, x = np.histogram(data)\n",
    "    plt.plot(x[0:len(x)-1], y)\n",
    "    y, x = np.histogram(rvs, bins = x)\n",
    "    plt.plot(x[0:len(x)-1], y, color='red')\n",
    "    plt.gca().set_yscale('log')\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.savefig('/Users/shwetanshusingh/Desktop/Snapchat/power-law/'+str(city)+'.pdf')\n",
    "\n",
    "    D,pval = ks_2samp(data, rvs)\n",
    "    fw.write(str(city)+','+str(params[0])+','+str(params[1])+','+str(params[2])+','+str(D)+','+\n",
    "        str(pval)+','+str(np.sum(spl.logpdf(data, *params)))+'\\n')\n",
    "\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/shwetanshusingh/Desktop/Snapchat/tile_driving_stats.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(['city', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "\n",
    "    for city in tqdm(grid_data.city.unique()):\n",
    "        data = grid_data[grid_data.city == city]\n",
    "        csv_writer.writerow([city] + [value for value in data['driving_tile_percent'].describe()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('/Users/shwetanshusingh/Desktop/Snapchat/tile_driving_stats.csv')\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/shwetanshusingh/Desktop/Snapchat/tile_driving_stats.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(['city', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "\n",
    "    for city in tqdm(data.city.unique()):\n",
    "        data = grid_data[grid_data.city == grid_data.city.unique()[0]]['driving_tile_percent'].values\n",
    "        data = list(data) + [0] * (len(grid_csv[grid_csv.city == grid_data.city.unique()[0]]) - len(data))\n",
    "        data = pd.DataFrame(data).describe()\n",
    "        csv_writer.writerow([city] + [value for value in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('/Users/shwetanshusingh/Desktop/Snapchat/tile_driving_stats.csv')\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df[(plot_df['mean'] > plot_df['std']) & (plot_df['count'] > 50)][['city', 'mean', 'std', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(plot_df[(plot_df['count'] > 50)]['mean'], plot_df[(plot_df['count'] > 50)]['std'], s=25, cmap=plt.cm.coolwarm, zorder=10)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set(xlabel='mean', ylabel='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data=plot_df, x='mean', y='std', legend=False, markers='o', fit_reg=True)\n",
    "ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set(xlabel='mean', ylabel='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.groupby('city').count()['non_driving'].reset_index().rename(columns={'non_driving': 'snap_count'})\n",
    "data = data.merge(df[df.non_driving == 0].groupby('city').count()['non_driving'].reset_index().rename(columns={'non_driving': 'driving_count'}))\n",
    "ax = sns.lmplot(data=data, x='snap_count', y='driving_count', legend=False, markers='o', fit_reg=True, order=2)\n",
    "ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set(xlabel='# Snaps', ylabel='# Driving Snaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data[['snap_count', 'driving_count']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "unclean_df = pd.read_csv('/Users/shwetanshusingh/Downloads/combined_v3.csv')\n",
    "\n",
    "df = unclean_df.dropna()\n",
    "\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "df.rename(columns={\"timestamp\": \"utc_timestamp\", \n",
    "                   \"local_time\": \"local_timestamp\",\n",
    "                    \"driving\": \"non_driving\"}, inplace=True)\n",
    "\n",
    "df.local_timestamp = pd.to_datetime(df['local_timestamp'])\n",
    "\n",
    "df['local_date'] = df.local_timestamp.dt.date\n",
    "df['local_time'] = df.local_timestamp.dt.time\n",
    "df['local_hour'] = df.local_timestamp.dt.hour\n",
    "df['local_minute'] = df.local_timestamp.dt.minute\n",
    "df['local_second'] = df.local_timestamp.dt.second\n",
    "\n",
    "data = df.groupby('local_hour').count()['id'].reset_index().rename(columns={'id': 'snap_count'})\n",
    "data = data.merge(df[df.non_driving == 0].groupby('local_hour').count()['id'].reset_index())\n",
    "data.rename(columns={'id': 'driving_count'}, inplace=True)\n",
    "data[['snap_count', 'driving_count']].corr()\n",
    "data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[(data.local_hour >= 18) | (data.local_hour < 2)].sum() / 8) / (data[(data.local_hour >=2) & (data.local_hour <18)].sum() / 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['snap_count', 'driving_count']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data[['snap_count', 'driving_count']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data=grid_data, x='snap_count', y='driving_count', \\\n",
    "                legend=False, markers='o', fit_reg=True, order=2, scatter_kws={\"s\":1})\n",
    "# ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set(xlabel='Number of Snaps', ylabel='Number of Driving Snaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data=grid_data, x='snap_count', y='driving_count', \\\n",
    "                legend=False, markers='o', fit_reg=True, order=2, scatter_kws={\"s\":1})\n",
    "ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set(xlabel='Number of Snaps', ylabel='Number of Driving Snaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/shwetanshusingh/Desktop/Snapchat/tile_driving_stats.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(['city', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'var'])\n",
    "\n",
    "    for city in tqdm(grid_data.city.unique()):\n",
    "        data = grid_data[grid_data.city == city]['driving_tile_percent'].values\n",
    "        data = list(data) + [0] * (len(grid_csv[grid_csv.city == city]) - len(data))\n",
    "        d = pd.DataFrame(data).describe()\n",
    "        csv_writer.writerow([city] + [value for value in d[0]] + [pd.DataFrame(data).var()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('/Users/shwetanshusingh/Desktop/Snapchat/tile_driving_stats.csv')\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df[(plot_df['mean'] > plot_df['std']) & (plot_df['count'] > 50)][['city', 'mean', 'std', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = grid_data.groupby('city').max().reset_index()[['city', 'driving_city_percent']]\n",
    "ax = sns.scatterplot(data=data, x='city', y='driving_city_percent')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(plot_df)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data=data, x='driving_city_percent', y='var', fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data=data, x='driving_city_percent', y='std', fit_reg=False)\n",
    "#                fit_reg=True, order=3, legend=False)\n",
    "# ax.set(xlabel='Hour of the day', ylabel='Number of Snaps')\n",
    "# plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=grid_data, x='driving_city_percent', y='snap_city_percent', fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('var', inplace=True)\n",
    "data.tail()['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "for city in data[data['count'] >= 50].city.unique():\n",
    "    q.append(sum(sorted(grid_data[grid_data.city == city].driving_city_percent, reverse=True)[:int(0.2 * data[data.city == city]['count'])]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "d = df.groupby('city').count()['id'].reset_index()\n",
    "for city in d[d.id > 1000].city.unique():\n",
    "    q.append(sum(sorted(grid_data[grid_data.city == city].driving_city_percent, reverse=True)[:int(0.1 * data[data.city == city]['count'])]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df[df.non_driving == 0].groupby('city').count()['id'] / df.groupby('city').count()['id']\n",
    "d.reset_index()['id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.non_driving == 0].count()['id'] / df.count()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBaseMap(default_location=[40.6452228,-74.015037], default_zoom_start=10):\n",
    "    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "new_york_df = df[df.city == \"New York\"]\n",
    "base_map = generateBaseMap()\n",
    "HeatMap(data=new_york_df[['lat', 'lon', 'non_driving']].groupby(['lat', 'lon']).sum().reset_index().values.tolist(), radius=8, max_zoom=10).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_df = df[(df.city == \"New York\") & (df.non_driving == 0)]\n",
    "base_map = generateBaseMap()\n",
    "HeatMap(data=new_york_df[['lat', 'lon', 'non_driving']].groupby(['lat', 'lon']).count().reset_index().values.tolist(), radius=8, max_zoom=10).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Riyadh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df = df[(df.city == \"Riyadh\") & (df.non_driving == 0)]\n",
    "base_map = generateBaseMap(default_location=[24.7241504,46.2620616])\n",
    "HeatMap(data=city_df[['lat', 'lon', 'non_driving']].groupby(['lat', 'lon']).count().reset_index().values.tolist(), radius=8, max_zoom=10).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df = df[(df.city == \"Riyadh\")]\n",
    "base_map = generateBaseMap(default_location=[24.7241504,46.2620616])\n",
    "HeatMap(data=city_df[['lat', 'lon', 'non_driving']].groupby(['lat', 'lon']).count().reset_index().values.tolist(), radius=8, max_zoom=10).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NYC Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geojson_grid(upper_right, lower_left, n=6):\n",
    "    \"\"\"Returns a grid of geojson rectangles, and computes the exposure in each section of the grid based on the vessel data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    upper_right: array_like\n",
    "        The upper right hand corner of \"grid of grids\" (the default is the upper right hand [lat, lon] of the USA).\n",
    "\n",
    "    lower_left: array_like\n",
    "        The lower left hand corner of \"grid of grids\"  (the default is the lower left hand [lat, lon] of the USA).\n",
    "\n",
    "    n: integer\n",
    "        The number of rows/columns in the (n,n) grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    list\n",
    "        List of \"geojson style\" dictionary objects   \n",
    "    \"\"\"\n",
    "\n",
    "    all_boxes = []\n",
    "\n",
    "    lat_steps = np.linspace(lower_left[0], upper_right[0], n+1)\n",
    "    lon_steps = np.linspace(lower_left[1], upper_right[1], n+1)\n",
    "\n",
    "    lat_stride = lat_steps[1] - lat_steps[0]\n",
    "    lon_stride = lon_steps[1] - lon_steps[0]\n",
    "\n",
    "    for lat in lat_steps[:-1]:\n",
    "        for lon in lon_steps[:-1]:\n",
    "            # Define dimensions of box in grid\n",
    "            upper_left = [lon, lat + lat_stride]\n",
    "            upper_right = [lon + lon_stride, lat + lat_stride]\n",
    "            lower_right = [lon + lon_stride, lat]\n",
    "            lower_left = [lon, lat]\n",
    "\n",
    "            # Define json coordinates for polygon\n",
    "            coordinates = [\n",
    "                upper_left,\n",
    "                upper_right,\n",
    "                lower_right,\n",
    "                lower_left,\n",
    "                upper_left\n",
    "            ]\n",
    "\n",
    "            geo_json = {\"type\": \"FeatureCollection\",\n",
    "                        \"properties\":{\n",
    "                            \"lower_left\": lower_left,\n",
    "                            \"upper_right\": upper_right\n",
    "                        },\n",
    "                        \"features\":[]}\n",
    "\n",
    "            grid_feature = {\n",
    "                \"type\":\"Feature\",\n",
    "                \"geometry\":{\n",
    "                    \"type\":\"Polygon\",\n",
    "                    \"coordinates\": [coordinates],\n",
    "                }\n",
    "            }\n",
    "\n",
    "            geo_json[\"features\"].append(grid_feature)\n",
    "\n",
    "            all_boxes.append(geo_json)\n",
    "\n",
    "    return all_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_right = [40.908600, -73.702201]\n",
    "lower_left = [40.495366, -74.247241]\n",
    "grid = get_geojson_grid(upper_right, lower_left, n=15)\n",
    "counts_array = []\n",
    "\n",
    "regional_counts = []\n",
    "\n",
    "for box in grid:\n",
    "    upper_right = box[\"properties\"][\"upper_right\"]\n",
    "    lower_left = box[\"properties\"][\"lower_left\"]\n",
    "\n",
    "    mask = (\n",
    "        (new_york_df.lat <= upper_right[1]) & (new_york_df.lat >= lower_left[1]) &\n",
    "        (new_york_df.lon <= upper_right[0]) & (new_york_df.lon >= lower_left[0])\n",
    "           )\n",
    "\n",
    "    region_incidents = len(new_york_df[mask])\n",
    "    regional_counts.append(region_incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca\n",
    "worst_region = max(regional_counts)\n",
    "m = generateBaseMap()\n",
    "for i, box in enumerate(grid):\n",
    "    geo_json = json.dumps(box)\n",
    "\n",
    "    color = plt.cm.Reds(regional_counts[i] / worst_region)\n",
    "    color = matplotlib.colors.to_hex(color)\n",
    "\n",
    "    gj = folium.GeoJson(geo_json,\n",
    "                        style_function=lambda feature, color=color: {\n",
    "                                                                        'fillColor': color,\n",
    "                                                                        'color':\"black\",\n",
    "                                                                        'weight': 2,\n",
    "                                                                        'dashArray': '5, 5',\n",
    "                                                                        'fillOpacity': 0.55,\n",
    "                                                                    })\n",
    "\n",
    "    m.add_child(gj)\n",
    "#     colormap = branca.colormap.linear.YlGn_09.scale(0, 1)\n",
    "#     colormap = colormap.to_step(index=[0, 0.3, 0.6, 0.8 , 1]) \n",
    "#     colormap.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"abcd.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>local_timestamp</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>url</th>\n",
       "      <th>non_driving</th>\n",
       "      <th>local_date</th>\n",
       "      <th>local_time</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>local_minute</th>\n",
       "      <th>local_second</th>\n",
       "      <th>local_weekday</th>\n",
       "      <th>local_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYp-nmZ_iQhJ8ZAWnUYZt1A...</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>26.890944</td>\n",
       "      <td>75.751022</td>\n",
       "      <td>1554046320000</td>\n",
       "      <td>2019-03-31 21:02:00</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.457</td>\n",
       "      <td>https://s.sc-cdn.net/fGnB8X2KoCi4dSuUBUYmCau84...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>21:02:00</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYSaz9jitYR-SCAWnWtL-KA...</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>42.003253</td>\n",
       "      <td>-87.891874</td>\n",
       "      <td>1554085028000</td>\n",
       "      <td>2019-03-31 21:17:08</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000</td>\n",
       "      <td>https://s.sc-cdn.net/CAlD3x7OwpfqIh0m9UuSjUvYC...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>21:17:08</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYrcLsJ9As3tReAWnQLZd2A...</td>\n",
       "      <td>Medina</td>\n",
       "      <td>24.436920</td>\n",
       "      <td>39.609041</td>\n",
       "      <td>1553975701000</td>\n",
       "      <td>2019-03-30 22:55:01</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000</td>\n",
       "      <td>https://s.sc-cdn.net/rbHaV9-XXeCu1DYyZjnlRw4qH...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>22:55:01</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYm5mVcCrKegBNAWnUqtxYA...</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.703049</td>\n",
       "      <td>-96.776003</td>\n",
       "      <td>1554050860000</td>\n",
       "      <td>2019-03-31 11:47:40</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>2.000</td>\n",
       "      <td>https://s.sc-cdn.net/WJ7w5lSCcs2LIn62Cv87ZYyVS...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>11:47:40</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYB3BAlpAwCkmmAWnYSG3EA...</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>25.242917</td>\n",
       "      <td>55.340233</td>\n",
       "      <td>1554111756000</td>\n",
       "      <td>2019-04-01 13:42:36</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000</td>\n",
       "      <td>https://s.sc-cdn.net/f3xl3b81sTrwnI04lVjrZRTnZ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>13:42:36</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id     city        lat  \\\n",
       "0  W7_EDlXWTBiXAEEniNoMPwAAYp-nmZ_iQhJ8ZAWnUYZt1A...   Jaipur  26.890944   \n",
       "1  W7_EDlXWTBiXAEEniNoMPwAAYSaz9jitYR-SCAWnWtL-KA...  Chicago  42.003253   \n",
       "2  W7_EDlXWTBiXAEEniNoMPwAAYrcLsJ9As3tReAWnQLZd2A...   Medina  24.436920   \n",
       "3  W7_EDlXWTBiXAEEniNoMPwAAYm5mVcCrKegBNAWnUqtxYA...   Dallas  32.703049   \n",
       "4  W7_EDlXWTBiXAEEniNoMPwAAYB3BAlpAwCkmmAWnYSG3EA...    Dubai  25.242917   \n",
       "\n",
       "         lon  utc_timestamp     local_timestamp scraped_date  duration  \\\n",
       "0  75.751022  1554046320000 2019-03-31 21:02:00   01_04_2019    10.457   \n",
       "1 -87.891874  1554085028000 2019-03-31 21:17:08   01_04_2019    10.000   \n",
       "2  39.609041  1553975701000 2019-03-30 22:55:01   01_04_2019    10.000   \n",
       "3 -96.776003  1554050860000 2019-03-31 11:47:40   01_04_2019     2.000   \n",
       "4  55.340233  1554111756000 2019-04-01 13:42:36   01_04_2019    10.000   \n",
       "\n",
       "                                                 url  non_driving  local_date  \\\n",
       "0  https://s.sc-cdn.net/fGnB8X2KoCi4dSuUBUYmCau84...            1  2019-03-31   \n",
       "1  https://s.sc-cdn.net/CAlD3x7OwpfqIh0m9UuSjUvYC...            1  2019-03-31   \n",
       "2  https://s.sc-cdn.net/rbHaV9-XXeCu1DYyZjnlRw4qH...            1  2019-03-30   \n",
       "3  https://s.sc-cdn.net/WJ7w5lSCcs2LIn62Cv87ZYyVS...            1  2019-03-31   \n",
       "4  https://s.sc-cdn.net/f3xl3b81sTrwnI04lVjrZRTnZ...            0  2019-04-01   \n",
       "\n",
       "  local_time  local_hour  local_minute  local_second local_weekday  local_day  \n",
       "0   21:02:00          21             2             0        Sunday         31  \n",
       "1   21:17:08          21            17             8        Sunday         31  \n",
       "2   22:55:01          22            55             1      Saturday         30  \n",
       "3   11:47:40          11            47            40        Sunday         31  \n",
       "4   13:42:36          13            42            36        Monday          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "df = pd.read_csv(\"/scratch/talsperre/combine_v4.csv\")\n",
    "df.rename(columns={\"timestamp\": \"utc_timestamp\", \n",
    "                   \"local_time\": \"local_timestamp\",\n",
    "                    \"driving\": \"non_driving\"}, inplace=True)\n",
    "\n",
    "df.local_timestamp = pd.to_datetime(df['local_timestamp'])\n",
    "\n",
    "df['local_date'] = df.local_timestamp.dt.date\n",
    "df['local_time'] = df.local_timestamp.dt.time\n",
    "df['local_hour'] = df.local_timestamp.dt.hour\n",
    "df['local_minute'] = df.local_timestamp.dt.minute\n",
    "df['local_second'] = df.local_timestamp.dt.second\n",
    "df['local_weekday'] = df.local_timestamp.dt.weekday_name\n",
    "df['local_day'] = df.local_timestamp.dt.day\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYZBYZksk...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dangerous/W7_EDlXWTBiXAEEniNoMPwAAYwsH034M7hVA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYU4ljwEu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYLlk0H8U...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYB5z-pIa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label\n",
       "0  non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYZBYZksk...      2\n",
       "1  dangerous/W7_EDlXWTBiXAEEniNoMPwAAYwsH034M7hVA...      1\n",
       "2  non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYU4ljwEu...      2\n",
       "3  non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYLlk0H8U...      2\n",
       "4  non-dangerous/W7_EDlXWTBiXAEEniNoMPwAAYB5z-pIa...      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", names=[\"id\", \"label\"], sep=\" \")\n",
    "test_df = pd.read_csv(\"test-gt.csv\", names=[\"id\", \"label\"], sep=\" \")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYZBYZksk_Aof_AWoO3JOeA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYwsH034M7hVAMAWmrnuCZA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYU4ljwEuz81xZAWmIO_iSA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYLlk0H8UKFo7oAWmWSaZwA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYB5z-pIaRycSuAWoEBDVYA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label\n",
       "0  W7_EDlXWTBiXAEEniNoMPwAAYZBYZksk_Aof_AWoO3JOeA...      2\n",
       "1  W7_EDlXWTBiXAEEniNoMPwAAYwsH034M7hVAMAWmrnuCZA...      1\n",
       "2  W7_EDlXWTBiXAEEniNoMPwAAYU4ljwEuz81xZAWmIO_iSA...      2\n",
       "3  W7_EDlXWTBiXAEEniNoMPwAAYLlk0H8UKFo7oAWmWSaZwA...      2\n",
       "4  W7_EDlXWTBiXAEEniNoMPwAAYB5z-pIaRycSuAWoEBDVYA...      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in train_df.iterrows():\n",
    "    cur_id = row['id']\n",
    "    new_id = cur_id.split(\"/\")[1]\n",
    "    train_df.at[i, 'id'] = new_id[:-4]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYQswOR5MGj4ZsAWmLW_0iA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYYX1439IMudCfAWmHZ3t5A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYe3UNt8vdH_yGAWmPSWyHA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYPi2k4bmCAFJaAWnuXATmA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYlJKEITtixxFUAWmswK_LA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label\n",
       "0  W7_EDlXWTBiXAEEniNoMPwAAYQswOR5MGj4ZsAWmLW_0iA...      1\n",
       "1  W7_EDlXWTBiXAEEniNoMPwAAYYX1439IMudCfAWmHZ3t5A...      1\n",
       "2  W7_EDlXWTBiXAEEniNoMPwAAYe3UNt8vdH_yGAWmPSWyHA...      1\n",
       "3  W7_EDlXWTBiXAEEniNoMPwAAYPi2k4bmCAFJaAWnuXATmA...      2\n",
       "4  W7_EDlXWTBiXAEEniNoMPwAAYlJKEITtixxFUAWmswK_LA...      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in test_df.iterrows():\n",
    "    cur_id = row['id']\n",
    "    new_id = cur_id.split(\"/\")[1]\n",
    "    test_df.at[i, 'id'] = new_id[:-4]\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest location classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>local_timestamp</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>url</th>\n",
       "      <th>non_driving</th>\n",
       "      <th>local_date</th>\n",
       "      <th>local_time</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>local_minute</th>\n",
       "      <th>local_second</th>\n",
       "      <th>local_weekday</th>\n",
       "      <th>local_day</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYwTAdatxvm2tYAWnT8Bh9A...</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>42.407909</td>\n",
       "      <td>-83.178556</td>\n",
       "      <td>1553999967000</td>\n",
       "      <td>2019-03-30 22:39:27</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>7.891678</td>\n",
       "      <td>https://s.sc-cdn.net/XGkFkyHgEkm78E3m4mas2f2Jf...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>22:39:27</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYcpF6cH2Fb9x5AWnVR3EwA...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>24.651636</td>\n",
       "      <td>46.604478</td>\n",
       "      <td>1554061345000</td>\n",
       "      <td>2019-03-31 22:42:25</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/4iDg-y4s4GTRBuAGuUvFEOacd...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>22:42:25</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYOw7XDzYeKLg_AWnVRJfUA...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>24.759436</td>\n",
       "      <td>46.732952</td>\n",
       "      <td>1554061029000</td>\n",
       "      <td>2019-03-31 22:37:09</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>https://s.sc-cdn.net/RNvslaj8DIKiyEFSD6rHmd8Ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>22:37:09</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYGH4fcyvlPF9mAWnWJYVsA...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>43.786870</td>\n",
       "      <td>-79.403115</td>\n",
       "      <td>1554075701000</td>\n",
       "      <td>2019-03-31 19:41:41</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/YM3nuGAEge6ACnlCgyYYXZCpw...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>19:41:41</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYsOyMsfZxDGkFAWnXCkcXA...</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>41.769686</td>\n",
       "      <td>-87.602511</td>\n",
       "      <td>1554090911000</td>\n",
       "      <td>2019-03-31 22:55:11</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/MwMYqmGmTZsAiSR7eVuZXhdOu...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>22:55:11</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id     city        lat  \\\n",
       "0  W7_EDlXWTBiXAEEniNoMPwAAYwTAdatxvm2tYAWnT8Bh9A...  Detroit  42.407909   \n",
       "1  W7_EDlXWTBiXAEEniNoMPwAAYcpF6cH2Fb9x5AWnVR3EwA...   Riyadh  24.651636   \n",
       "2  W7_EDlXWTBiXAEEniNoMPwAAYOw7XDzYeKLg_AWnVRJfUA...   Riyadh  24.759436   \n",
       "3  W7_EDlXWTBiXAEEniNoMPwAAYGH4fcyvlPF9mAWnWJYVsA...  Toronto  43.786870   \n",
       "4  W7_EDlXWTBiXAEEniNoMPwAAYsOyMsfZxDGkFAWnXCkcXA...  Chicago  41.769686   \n",
       "\n",
       "         lon  utc_timestamp     local_timestamp scraped_date   duration  \\\n",
       "0 -83.178556  1553999967000 2019-03-30 22:39:27   01_04_2019   7.891678   \n",
       "1  46.604478  1554061345000 2019-03-31 22:42:25   01_04_2019  10.000000   \n",
       "2  46.732952  1554061029000 2019-03-31 22:37:09   01_04_2019   2.000000   \n",
       "3 -79.403115  1554075701000 2019-03-31 19:41:41   01_04_2019  10.000000   \n",
       "4 -87.602511  1554090911000 2019-03-31 22:55:11   01_04_2019  10.000000   \n",
       "\n",
       "                                                 url  non_driving  local_date  \\\n",
       "0  https://s.sc-cdn.net/XGkFkyHgEkm78E3m4mas2f2Jf...            1  2019-03-30   \n",
       "1  https://s.sc-cdn.net/4iDg-y4s4GTRBuAGuUvFEOacd...            0  2019-03-31   \n",
       "2  https://s.sc-cdn.net/RNvslaj8DIKiyEFSD6rHmd8Ph...            0  2019-03-31   \n",
       "3  https://s.sc-cdn.net/YM3nuGAEge6ACnlCgyYYXZCpw...            0  2019-03-31   \n",
       "4  https://s.sc-cdn.net/MwMYqmGmTZsAiSR7eVuZXhdOu...            1  2019-03-31   \n",
       "\n",
       "  local_time  local_hour  local_minute  local_second local_weekday  local_day  \\\n",
       "0   22:39:27          22            39            27      Saturday         30   \n",
       "1   22:42:25          22            42            25        Sunday         31   \n",
       "2   22:37:09          22            37             9        Sunday         31   \n",
       "3   19:41:41          19            41            41        Sunday         31   \n",
       "4   22:55:11          22            55            11        Sunday         31   \n",
       "\n",
       "   label  \n",
       "0      2  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.merge(df, train_df, on=['id'], how='inner')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>local_timestamp</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>url</th>\n",
       "      <th>non_driving</th>\n",
       "      <th>local_date</th>\n",
       "      <th>local_time</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>local_minute</th>\n",
       "      <th>local_second</th>\n",
       "      <th>local_weekday</th>\n",
       "      <th>local_day</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYrdGw06ScXhj9AWnUcbEeA...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>24.588753</td>\n",
       "      <td>46.693422</td>\n",
       "      <td>1554047317000</td>\n",
       "      <td>2019-03-31 18:48:37</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>https://s.sc-cdn.net/6bZHWmBxWKo6Gqahr4PVLXmIF...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>18:48:37</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYWbOiJNAgaSGGAWnWyqxsA...</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>41.877486</td>\n",
       "      <td>-87.638681</td>\n",
       "      <td>1554086613000</td>\n",
       "      <td>2019-03-31 21:43:33</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.003333</td>\n",
       "      <td>https://s.sc-cdn.net/S423RBGo1JAqslRxevgzmmjcz...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>21:43:33</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAY0MmnuWya-4gRAWnW6YZlA...</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.783900</td>\n",
       "      <td>-96.797382</td>\n",
       "      <td>1554088752000</td>\n",
       "      <td>2019-03-31 22:19:12</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/ZghdfIYVx-ufQicHKiXQ7CQ9W...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>22:19:12</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYGV_ny7hwC9pVAWnXPb-nA...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>24.678586</td>\n",
       "      <td>46.772483</td>\n",
       "      <td>1554094062000</td>\n",
       "      <td>2019-04-01 07:47:42</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/6dpHGbghy9Ady_JbwBihMmR3b...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>07:47:42</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W7_EDlXWTBiXAEEniNoMPwAAYN18ncibHUr8hAWnYsyzbA...</td>\n",
       "      <td>Amritsar</td>\n",
       "      <td>31.627025</td>\n",
       "      <td>74.840292</td>\n",
       "      <td>1554118724000</td>\n",
       "      <td>2019-04-01 17:08:44</td>\n",
       "      <td>01_04_2019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>https://s.sc-cdn.net/_iz1ezsz2dbUfyeAaJTnA4l3m...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>17:08:44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id      city        lat  \\\n",
       "0  W7_EDlXWTBiXAEEniNoMPwAAYrdGw06ScXhj9AWnUcbEeA...    Riyadh  24.588753   \n",
       "1  W7_EDlXWTBiXAEEniNoMPwAAYWbOiJNAgaSGGAWnWyqxsA...   Chicago  41.877486   \n",
       "2  W7_EDlXWTBiXAEEniNoMPwAAY0MmnuWya-4gRAWnW6YZlA...    Dallas  32.783900   \n",
       "3  W7_EDlXWTBiXAEEniNoMPwAAYGV_ny7hwC9pVAWnXPb-nA...    Riyadh  24.678586   \n",
       "4  W7_EDlXWTBiXAEEniNoMPwAAYN18ncibHUr8hAWnYsyzbA...  Amritsar  31.627025   \n",
       "\n",
       "         lon  utc_timestamp     local_timestamp scraped_date   duration  \\\n",
       "0  46.693422  1554047317000 2019-03-31 18:48:37   01_04_2019   7.200000   \n",
       "1 -87.638681  1554086613000 2019-03-31 21:43:33   01_04_2019  10.003333   \n",
       "2 -96.797382  1554088752000 2019-03-31 22:19:12   01_04_2019  10.000000   \n",
       "3  46.772483  1554094062000 2019-04-01 07:47:42   01_04_2019  10.000000   \n",
       "4  74.840292  1554118724000 2019-04-01 17:08:44   01_04_2019  10.000000   \n",
       "\n",
       "                                                 url  non_driving  local_date  \\\n",
       "0  https://s.sc-cdn.net/6bZHWmBxWKo6Gqahr4PVLXmIF...            1  2019-03-31   \n",
       "1  https://s.sc-cdn.net/S423RBGo1JAqslRxevgzmmjcz...            1  2019-03-31   \n",
       "2  https://s.sc-cdn.net/ZghdfIYVx-ufQicHKiXQ7CQ9W...            0  2019-03-31   \n",
       "3  https://s.sc-cdn.net/6dpHGbghy9Ady_JbwBihMmR3b...            1  2019-04-01   \n",
       "4  https://s.sc-cdn.net/_iz1ezsz2dbUfyeAaJTnA4l3m...            0  2019-04-01   \n",
       "\n",
       "  local_time  local_hour  local_minute  local_second local_weekday  local_day  \\\n",
       "0   18:48:37          18            48            37        Sunday         31   \n",
       "1   21:43:33          21            43            33        Sunday         31   \n",
       "2   22:19:12          22            19            12        Sunday         31   \n",
       "3   07:47:42           7            47            42        Monday          1   \n",
       "4   17:08:44          17             8            44        Monday          1   \n",
       "\n",
       "   label  \n",
       "0      2  \n",
       "1      2  \n",
       "2      1  \n",
       "3      2  \n",
       "4      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.merge(df, test_df, on=['id'], how='inner')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[[\"lat\", \"lon\"]]\n",
    "y_train = train_df[[\"non_driving\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[[\"lat\", \"lon\"]]\n",
    "y_test = test_df[[\"non_driving\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talsperre/torch4env/lib/python3.5/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50building tree 2 of 50building tree 3 of 50\n",
      "\n",
      "building tree 4 of 50\n",
      "\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50building tree 18 of 50\n",
      "\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50building tree 24 of 50\n",
      "\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50building tree 37 of 50\n",
      "\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=50, verbose=2, n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7153482082488167\n",
      "F1 score:  0.8192357234864749\n",
      "Precision score:  0.7976588628762542\n",
      "Recall score:  0.8420123565754634\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score: \", metrics.f1_score(y_test, y_pred))\n",
    "print(\"Precision score: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall score: \", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.367     0.301     0.331       346\n",
      "           1      0.798     0.842     0.819      1133\n",
      "\n",
      "    accuracy                          0.715      1479\n",
      "   macro avg      0.583     0.571     0.575      1479\n",
      "weighted avg      0.697     0.715     0.705      1479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred, classes=['Driving', 'Non-Driving'], title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talsperre/torch4env/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/talsperre/torch4env/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df[[\"local_hour\", \"local_minute\", \"local_weekday\"]]\n",
    "y_train = train_df[[\"non_driving\"]]\n",
    "\n",
    "X_train[\"local_weekday\"] = X_train[\"local_weekday\"].astype('category')\n",
    "X_train[\"local_weekday\"] = X_train[\"local_weekday\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talsperre/torch4env/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/talsperre/torch4env/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df[[\"local_hour\", \"local_minute\", \"local_weekday\"]]\n",
    "y_test = test_df[[\"non_driving\"]]\n",
    "\n",
    "X_test[\"local_weekday\"] = X_test[\"local_weekday\"].astype('category')\n",
    "X_test[\"local_weekday\"] = X_test[\"local_weekday\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talsperre/torch4env/lib/python3.5/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50building tree 12 of 50\n",
      "\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "\n",
      "building tree 21 of 50building tree 22 of 50\n",
      "\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50building tree 31 of 50\n",
      "\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50building tree 44 of 50\n",
      "\n",
      "building tree 45 of 50building tree 46 of 50\n",
      "\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=50, verbose=2, n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6646382691007438\n",
      "F1 score:  0.7867583834909716\n",
      "Precision score:  0.7669740150880134\n",
      "Recall score:  0.8075904677846425\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score: \", metrics.f1_score(y_test, y_pred))\n",
    "print(\"Precision score: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall score: \", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.238     0.197     0.215       346\n",
      "           1      0.767     0.808     0.787      1133\n",
      "\n",
      "    accuracy                          0.665      1479\n",
      "   macro avg      0.502     0.502     0.501      1479\n",
      "weighted avg      0.643     0.665     0.653      1479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
